Interactive Symposium: Knowledge building analytics: Where we are and where we are headed================================The Issue---------Knowledge Forum is one of the earliest computer-supported collaborative environments to support embedded formative assessment tools. With the current rebuild of Knowledge Forum going on, it becomes important to review where we were and where we are in terms of knowledge building analytics and make informed decisions on where we should be headed in building next-generation analytics.Major Goals-----------This interactive symposium explores theoretical, design, and technological aspects of knowledge building analytics. It systematically reviews analytic tools that have been built for knowledge building. It aims to conceptualize knowledge building analytics based on discussion of epistemology, assessment, pedagogy, and stakeholder needs. Informed by this discussion, it goes further to explore indicators that matter for knowledge building, and shifts to discuss design of knowledge building analytics. A demo of building analytic tools with the new Knowledge Forum APIs will be provided and several design documents will be presented. Through extensive discussion and collaboration among the participants, we expect to bring together a coherent conception of knowledge building analytics, a few new designs of analytic tools, and a few teams who are motivated to implement their designs with the API.Key Components--------------### Where we are: A review of knowledge building analyticsA brief yet systematic review of analytic tools developed for knowledge building and Knowledge Forum will be presented at the beginning of this symposium, to inform later discussion and design of next-generation knowledge building analytics.### A conceptual framework of knowledge building analytics: Epistemology, assessment, and moreExploring epistemological assumptions is critical for developing analytics (Knight, Buckingham Shum, & Littleton, 2013). Epistemology, concerned with “the nature of knowledge,” may implicitly dictate what we assess. This presentation will survey epistemological underpinnings of knowledge building and their implications for design of analytic tools.### Knowledge building indicators that matterThis interactive section will start with a short review of important knowledge building indicators present in literature (e.g., Zhang & Sun, 2011). Then we will open up discussion for knowledge building indicators that matter.### Assessment that spurs the emergence of new competenciesWhile it is important to ensure the attainment of educational goals, to address 21st century needs of education also calls for the discovery of new competencies; “[r]ather than simply extrapolating from existing goals or expert-identified objectives, new goals can emerge from the capacities that students demonstrate in supportive environments” (Scardamalia, Bransford, Kozma, & Quellmalz, 2012). This section will discuss designs to support the emergence of new competencies that go beyond current “best-practice” in the field of learning analytics.### Design of theoretically-informed analytics for knowledge buildingDecision making in analytic tool design is less related to aesthetics than to underlying theories. This interactive section will begin with an articulation of this argument, with case studies of analytic tool design. Then participants are invited to form small groups, with a favourable mix of researchers, teachers, designers, and programmers if possible, to tackle specific design problems of their choice.### Building analytic tools with Knowledge Forum APIsThe new Knowledge Forum API allows flexible implementation of analytic tools. This section will feature a demo of the API in a number of programming languages (including Java, Python, and R). After this demo, participants are encouraged to work with their teams to implement design ideas during this symposium and the rest of the conference as well.### Assessments that empower teachers and students: Pedagogical interventions around knowledge building analyticsWell designed analytics do not warrant improved knowledge building in a community. It has been recognized that the design of learning analytics interventions should go hand in hand with analytics so that tools, data, and reports are taken up and used properly (Wise, 2014). How do teachers and students perceive designed analytic tools? How do we harness the power of algorithms while granting enough epistemic to knowledge builders? How should we organize dialogues around analytic tools? This section will explore issues in design of pedagogical interventions to empower teachers and students to maximize the usefulness of analytics.### A Debrief near the end of conferenceWe expect this symposium to catalyse dialogues and collaboration on knowledge building analytics. We look forward to keep our dialogues and implementation efforts going during the conference. By the end of the conference, we hope to hold a debrief of the outcomes of this symposium.Expected Audience-----------------A mix of researchers, classroom practitioners, designers, and software engineers who are interested in knowledge building analytics.Proposed Length of Session--------------------------6-8 hoursReferences----------- Knight, S., Buckingham Shum, S., & Littleton, K. (2013). Epistemology, pedagogy, assessment and learning analytics. In Proceedings of the Third International Conference on Learning Analytics and Knowledge - LAK ’13 (p. 75). New York, New York, USA: ACM Press. doi:10.1145/2460296.2460312- Scardamalia, M., Bransford, J. D., Kozma, B., & Quellmalz, E. (2012). New Assessments and Environments for Knowledge Building. In Assessment and Teaching of 21st Century Skills (pp. 231–300). Springer. doi:10.1007/978-94-007-2324-5_5- Wise, A. F. (2014). Designing pedagogical interventions to support student use of learning analytics. In Proceedins of the Fourth International Conference on Learning Analytics And Knowledge - LAK ’14 (pp. 203–211). New York, New York, USA: ACM Press. doi:10.1145/2567574.2567588- Zhang, J., & Sun, Y. (2011). Quantified measures of online discourse as knowledge building indicators. In H. Spada, S. G., N. Miyake, & N. Law (Eds.), Connecting computer-supported collaborative learning to policy and practice: CSCL2011 conference proceedings (Vol. 1, pp. 72–79). Hong Kong SAR, China: ISLS.